{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install TensorFlow2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All imports are present below which are used as per requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import glob\n",
    "# from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# from imblearn.ensemble import EasyEnsembleClassifier\n",
    "# from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "# bagged decision trees on an imbalanced classification problem\n",
    "from numpy import mean\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "# import seaborn as sns\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC_clf=SVC()\n",
    "DTree_clf = DecisionTreeClassifier()\n",
    "dtree_bagging_model = BaggingClassifier(base_estimator=DTree_clf, n_estimators=50, random_state=12)\n",
    "random_forest = RandomForestClassifier(n_estimators=1000,random_state=0)\n",
    "extra_trees = ExtraTreesClassifier(n_estimators=100, random_state=12)\n",
    "gnb=GaussianNB()\n",
    "model=AdaBoostClassifier(n_estimators=32)\n",
    "m1=AdaBoostClassifier(n_estimators=31)\n",
    "xgb=GradientBoostingClassifier()\n",
    "# qda=QuadraticDiscriminantAnalysis()\n",
    "clfMLP = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "pipe = make_pipeline(scaler,xgb)\n",
    "clf = lgb.LGBMClassifier(kernel= 'rbf',C = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACAN</th>\n",
       "      <th>AGER</th>\n",
       "      <th>ALPK1</th>\n",
       "      <th>ANKRD17</th>\n",
       "      <th>APOB</th>\n",
       "      <th>APPL1</th>\n",
       "      <th>APPL2</th>\n",
       "      <th>ARRB2</th>\n",
       "      <th>ASGR1</th>\n",
       "      <th>ASGR2</th>\n",
       "      <th>...</th>\n",
       "      <th>UBE2N</th>\n",
       "      <th>UBE2V1</th>\n",
       "      <th>UBQLN1</th>\n",
       "      <th>UFD1</th>\n",
       "      <th>UNC93B1</th>\n",
       "      <th>USP17L2</th>\n",
       "      <th>VCAN</th>\n",
       "      <th>WDFY1</th>\n",
       "      <th>XIAP</th>\n",
       "      <th>ZCCHC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-1.17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.31</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-1.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.62</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>0.11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.32</td>\n",
       "      <td>-0.59</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.17</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.90</td>\n",
       "      <td>-0.22</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1.84</td>\n",
       "      <td>0.71</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>-0.28</td>\n",
       "      <td>-1.26</td>\n",
       "      <td>-0.61</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.30</td>\n",
       "      <td>-0.73</td>\n",
       "      <td>0.70</td>\n",
       "      <td>2.26</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>-0.77</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.47</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.33</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>-0.38</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.29</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.40</td>\n",
       "      <td>-0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.56</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.30</td>\n",
       "      <td>-1.16</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>2.05</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>0.43</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>1.10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.53</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>-0.67</td>\n",
       "      <td>-0.37</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>0.97</td>\n",
       "      <td>-0.30</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACAN  AGER  ALPK1  ANKRD17  APOB  APPL1  APPL2  ARRB2  ASGR1  ASGR2  ...  \\\n",
       "0 -0.42  0.00  -0.21    -0.45 -0.13  -0.10  -0.79  -0.79  -0.23  -0.70  ...   \n",
       "1 -0.31 -0.02   0.92     0.72  0.20  -1.28   1.00  -0.62  -0.32   0.11  ...   \n",
       "2 -0.17 -0.55  -1.29    -0.96 -0.21  -0.90  -0.82  -0.90  -0.22  -0.75  ...   \n",
       "3 -0.30 -0.73   0.70     2.26 -0.21  -1.08  -0.77   0.15   0.47  -0.49  ...   \n",
       "4 -0.56  0.74   0.30    -1.16 -0.21   2.05  -0.46   0.43  -0.50   1.10  ...   \n",
       "\n",
       "   UBE2N  UBE2V1  UBQLN1  UFD1  UNC93B1  USP17L2  VCAN  WDFY1  XIAP  ZCCHC3  \n",
       "0   0.54    0.42    1.33 -1.17     0.06    -0.37 -0.53  -0.41 -0.64    0.50  \n",
       "1   0.00   -1.12    0.50 -0.32    -0.59    -0.37  0.07   0.63  0.32   -0.21  \n",
       "2   1.84    0.71   -0.00  2.23     0.05     1.58 -0.28  -1.26 -0.61    0.45  \n",
       "3   0.97    0.23    1.33 -0.72    -0.38    -0.37 -0.29   0.86  0.40   -0.95  \n",
       "4  -0.48    0.03   -0.53 -0.50    -0.67    -0.37 -0.51   0.97 -0.30    1.07  \n",
       "\n",
       "[5 rows x 318 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd=os.getcwd()\n",
    "filepathTrain=os.path.join(pwd,\"kaggle_train.csv\")\n",
    "training_data=pd.read_csv(filepathTrain)\n",
    "y=training_data[\"Labels\"]\n",
    "training_data.drop(\"Labels\",axis=1,inplace=True)\n",
    "training_data.drop(\"ID\",axis=1,inplace=True)\n",
    "X = training_data\n",
    "X1 = pd.DataFrame(scaler.fit_transform(X))\n",
    "X1.columns=X.columns\n",
    "X1.head()      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions of feature selection techniques are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Model_ETC(X1, y):\n",
    "    X=X1\n",
    "    clf = m1\n",
    "    clf = clf.fit(X, y)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    sf = model.transform(X)\n",
    "    ET_sc = X.columns[model.get_support(indices=True)]\n",
    "    etC=X[ET_sc]\n",
    "    return [etC,ET_sc]\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold #Import the library\n",
    "def Model_VarThreshold(X1):\n",
    "    sel = VarianceThreshold(1.0) # This will remove all zero-variance features\n",
    "    sf = sel.fit_transform(X1) # The file will be saved in sf\n",
    "    var_sc = X1.columns[sel.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "    var_th=X1[var_sc]\n",
    "    return var_th\n",
    "\n",
    "\n",
    "def Model_kendall(X1, y):\n",
    "    X = X1\n",
    "    cor = X.corr(method='kendall') # Calculate Correlation between each variable\n",
    "    cor_target = abs(y) #Correlation with output variable\n",
    "    relevant_features = cor_target[cor_target>=0.1]\n",
    "    # kendall=X.columns[relevant_features.get_support(indices=True)] #Selecting correlated features above than the given threshold\n",
    "    kendall_sc= pd.DataFrame(relevant_features).index #This saves the columns names in sc variable\n",
    "    #This will show the first\n",
    "    kendall=X.iloc[:,kendall_sc]\n",
    "    return [kendall,kendall_sc]     #returns appropriate data as well as eligible columns for that data\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression   \n",
    "def Model_LR(X1, y):\n",
    "    X=X1\n",
    "    lr = xgb\n",
    "    rfe = RFE(lr) #It assigns weights to features using logistic regression\n",
    "    sf = rfe.fit(X, y)  # It learns relationship and transfrom the data\n",
    "    RFE_sc = X.columns[rfe.get_support(indices=True)] #This saves the columns names in sc variable\n",
    "    rfeC=X[RFE_sc]\n",
    "    return rfeC\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "def Model_ETC(X1, y):\n",
    "    X=X1\n",
    "    clf = m1\n",
    "    clf = clf.fit(X, y)\n",
    "    model = SelectFromModel(clf, prefit=True)\n",
    "    sf = model.transform(X)\n",
    "    ET_sc = X.columns[model.get_support(indices=True)]\n",
    "    etC=X[ET_sc]\n",
    "    return [etC,ET_sc]\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "def Model_LinearSVC(X1, y):\n",
    "    X=X1\n",
    "    lr = LogisticRegression()\n",
    "    rfe = RFE(lr) #It assigns weights to features using logistic regression\n",
    "    sf = rfe.fit(X, y)  # It learns relationship and transfrom the data\n",
    "\n",
    "    l1_sc = X.columns[rfe.get_support(indices=True)]\n",
    "    l1C=X[l1_sc]\n",
    "    return [l1C,l1_sc]  \n",
    "\n",
    "z= PCA(n_components=10).fit_transform(X1)   #principal component analysis technique \n",
    "\n",
    "# df = pd.DataFrame()\n",
    "# df[\"y\"] = y\n",
    "# df[\"comp-1\"] = z[:,0]\n",
    "# df[\"comp-2\"] = z[:,1]\n",
    "\n",
    "# sns.scatterplot(x=\"comp-1\", y=\"comp-2\", hue=df.y.tolist(),\n",
    "#                 palette=sns.color_palette(\"hls\", 10),\n",
    "#                 data=df).set(title=\"MNIST data T-SNE projection\")\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kend = Model_kendall(X1,y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.30, random_state=19)\n",
    "\n",
    "# param_grid = {'C': [1,10,100], \n",
    "#               'kernel': ['poly','rbf']} \n",
    "  \n",
    "# grid = GridSearchCV(lgb.LGBMClassifier(), param_grid, refit = True, verbose = 5)    #applying grid search after LGBM model\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# grid.score(X_test, y_test)\n",
    "\n",
    "# # accuracy_score(y_test,y_pred)\n",
    "# # accuracy_score(predictions , y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lazy test for check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = LazyClassifier(verbose=0,\n",
    "#                      ignore_warnings=True, \n",
    "#                      custom_metric=None)\n",
    "# models, predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "# # models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k repeats check , or the main system used for achieving improved classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.702\n",
      "acc: 0.727\n",
      "acc: 0.734\n",
      "acc: 0.719\n",
      "0.7206065759637188\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=AdaBoostClassifier(n_estimators=32)\n",
    "# kend = Model_kendall(X1,y)\n",
    "\n",
    "# rf2=RandomForestClassifier(C=0.11,gamma=1,kernel='rbf')\n",
    "etC=Model_ETC(X1,y)\n",
    "# kend = Model_kendall(X1,y)\n",
    "# etC=Model_VarThreshold(etC1[0])\n",
    "clfMLP = MLPClassifier(solver='lbfgs', alpha=1e-2,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "# voting_clf = VotingClassifier(estimators=[ ('hh',clfMLP),('hh',random_forest),], voting='hard')\n",
    "avg=0\n",
    "for i in range(1,5):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=3*i)\n",
    "    scores = cross_val_score(model,etC[0], y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    avg=avg+mean(scores)\n",
    "    print('acc: %.3f' % mean(scores))\n",
    "print(avg/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostClassifier(n_estimators=32)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostClassifier</label><div class=\"sk-toggleable__content\"><pre>AdaBoostClassifier(n_estimators=32)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostClassifier(n_estimators=32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(etC[0],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators': [8,10, 30],\n",
    "#     'sampling_strategy':['all','not majority','auto'],\n",
    "#     'n_jobs':[-1]\n",
    "# }\n",
    "\n",
    "# grid = GridSearchCV(EasyEnsembleClassifier(), param_grid, refit = True, verbose = 3)\n",
    "# grid.fit(training_data, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print best parameter after tuning\n",
    "# print(grid.best_params_)\n",
    "  \n",
    "# print how our model looks after hyper-parameter tuning\n",
    "# print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading test file , preparing data to be used and dumping output in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepathTest=os.path.join(pwd,\"kaggle_test.csv\")\n",
    "test_data=pd.read_csv(filepathTest)\n",
    "testdata=test_data[etC[1]]\n",
    "\n",
    "tX = pd.DataFrame(scaler.fit_transform(testdata))\n",
    "tX.columns=testdata.columns\n",
    "# tX.head() \n",
    "id=test_data[\"ID\"]\n",
    "\n",
    "predictionsTest=model.predict(tX)\n",
    "Y_prob = [x[1] for x in model.predict_proba(tX)]\n",
    "df = pd.DataFrame(id, columns = [\"ID\"])\n",
    "# df2= pd.DataFrame(id, columns = [\"ID\"])\n",
    "df[\"Labels\"]=predictionsTest\n",
    "predictionsTest\n",
    "df.to_csv('sss.csv',index=False)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "ea95c43063b92d41adec3398bc725756afb659bb66ae81e9e811dea50f9ef364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
